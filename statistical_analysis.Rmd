---
title: "Statistical Analysis"
output: 
  html_document:
    code_folding: hide
    always_allow_html: true
    toc: true
    toc_float: true
---

```{r preamble, echo = FALSE, message = FALSE, warning = FALSE}
# load necessary packages
library(tidyverse)
library(glmnet)
library(tidymodels)
library(performance)
library(olsrr)
library(kableExtra)

# set knitr defaults
knitr::opts_chunk$set(
    echo      = TRUE
  , message   = FALSE
  , warning   = FALSE
  , fig.align = "center"
)

# set theme defaults
theme_set(
  theme_bw() +
  theme(
    legend.position = "bottom"
    , plot.title    = element_text(hjust = 0.5)
    , plot.subtitle = element_text(hjust = 0.5)    
    , plot.caption  = element_text(hjust = 0.0)
  )
)

# set color scale defaults
options(
    ggplot2.continuous.colour = "viridis"
  , ggplot2.continuous.fill   = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete   = scale_fill_viridis_d
```



## Methodology

For our statistical analysis, we consider a linear regression. In particular, let $S$ denote the set of PUMAs in NYC, and let $y_s$ denote our outcome of interest. We consider the latent variable model
	$$ y_s = \xi_s' \beta + \varepsilon_s $$
for each $s \in S$, where $\xi_s$ is a vector of PUMA-level means of data from the census and $\beta$ is a vector of parameters. There are two challenges in considering such a model: (1) we know historically that NYC neighborhoods, particularly those within boroughs, are subject to spatial correlation; and (2) because the census data is recorded at the interview level, we do not observe the group-level means $\xi_s$.

In order to address (1), we employ heteroscedasticity-robust White standard errors to deal with the potential threat of spatial correlation. We find that all of our coefficient estimates retain their significance under the adjusted standard errors, and hence we leave this check on robustness to the appendix.

More interesting is the challenge presented in (2). For each $s \in S$, suppose we observe $i \in \{ 1, \ldots, n_s \}$ individual-level interviews. It is natural to consider the group mean
	$$ \bar{X}_s \equiv \frac{1}{n_s} \sum_{i = 1}^{n_s} X_{is}. $$
However, as shown in [Croon and Veldhoven](https://psycnet.apa.org/fulltext/2007-03329-003.pdf) (2007), it is generally the case that using the observed group mean $\bar{X}_s$ as an estimator of $\xi_s$ will lead to biased regression coefficients. Thus, we address (2) by following the procedure outlined by Croon and Veldhoven to re-weight our group means and obtain adjusted group means $\tilde{X}_s$. In particular, let $\hat{\Sigma}_{\xi \xi}$ and $\hat{\Sigma}_{\nu \nu}$ denote the usual ANOVA estimates of the between- and within-group variation matrices, respectively. The adjusted group means are then given by
	$$ \tilde{X}_s \equiv \bar{X}' (I - W_s) + \bar{X}_s' W_s, \quad \text{where} $$
	$$ W_s \equiv \left( \hat{\Sigma}_{\xi \xi} + \hat{\Sigma}_{\nu \nu} / n_s \right)^{-1} \hat{\Sigma}_{\xi \xi} $$
and $I$ denotes the identity matrix. Intuitively, the weight matrix $W_s$ acts as a shrinkage estimator, shrinking the observed group mean $\bar{X}_s$ in the direction of the citywide mean $\bar{X}$. Observe that as the between-group variation dominates relative to the within-group variation, $W_s$ converges to the identity matrix $I$, and hence the adjusted group mean $\tilde{X}_s$ converges to the observed group mean $\bar{X}_s$. That is, the better we can see the neighborhood signals through the noise, the less we need to penalize the observed means.

With our unbiased estimates $\xi_s$ in tow, we then proceeed to model selection. Given that there are $|S| = 55$ PUMAs, we must be careful to avoid overfitting our model. As such, we empoloy a stepwise algorithm with an objective function of minimizing the AIC. In this way, we penalize models subject to overfitting and obtain an appropriately parsimonius selection of predictors. Now that our theoretical concerns have been addressed, we can finally discuss our findings!

__A word of caution:__ If the reader is considering such a macro-micro model for their own research, be advised that _there is a typographical error in the Croon and Veldhoven paper_. When estimating the unbiased between- and within-group covariance matrices, they inadvertently swap the divisors for their MSA and MSE. In large samples, this error can lead to weight matrices $W_s$ that are not positive definite, which in turn leads to a non-convex combination of $\bar{X}$ and $\bar{X}_s$, which further leads to immense woe for the programmer who cannot understand why his unbiased estimates for non-negative random variables are somehowe negative.



## Results

```{r fetch_data}
# pull in health outcomes to be merged
outcome_by_year <- 
  # read in health outcomes by year
  read_csv("./data/outcome_puma_by_year.csv") %>%
  # harmonize puma variable for merge
  rename(puma = puma10)

# standardize inputs for consistent interpretation
standardized_data <-
  # read in unbiased group means for inputs
  read_csv("./data/unbiased_group_means.csv") %>%
  # apply the scale function to appropriate columns
  mutate_at(-c(1, 2), ~ c(scale(., center = FALSE))) %>%
  # merge with health outcomes
  merge(outcome_by_year, by = "puma")

# store optimal linear model
best_model <- lm(
  puma_hosp_rate_2020 ~
    # unemployment rate
    employment_not_in_labor_force +
    # fraction of spanish speakers
    language_spanish +
    # fraction of english speakers
    language_english +
    # fraction of those born in the us
    birthplace_us +
    # fraction of those with bachelors degree
    education_bachelors_degree +
    # fraction of those born in the us
    birthplace_us +
    # fraction of those using public health insurance
    health_insurance_public +
    # average personal income
    personal_income +
    # language-birthplace interaction
    language_english:birthplace_us + 
    # education-income interaction
    education_bachelors_degree:personal_income +
    # insurance-income interaction
    health_insurance_public:personal_income
  , data = standardized_data
)

# store full model to compute mallow's cp
full_model <- lm(
  puma_hosp_rate_2020 ~
    # unemployment rate
    (employment_not_in_labor_force +
    # fraction of spanish speakers
    language_spanish +
    # fraction of english speakers
    language_english +
    # fraction of those born in the us
    birthplace_us +
    # fraction of those with bachelors degree
    education_bachelors_degree +
    # fraction of those born in the us
    birthplace_us +
    # fraction of those using public health insurance
    health_insurance_public +
    # average personal income
    personal_income)^2
  , data = standardized_data
)

# create professional table for regression output
best_model %>%
  # summarize regression output
  summary() %>%
  # tidy regression output
  broom::tidy() %>%
  # map to a kable table
  kbl(
      col.names   = c("Predictor", "Estimate", "SE", "t-statistic", "p-value")
    , digits      = c(1, rep(0, 2), 2, 4)
    , format.args = list(big.mark = ',')
  ) %>%
  # further map to a more professional-looking table
  kable_paper("striped", full_width = F) %>%
  # make variable names bold
  column_spec(1, bold = T)
```

For the sake of interpretation, all predictors above have been partially standardized. That is, for each predictor $x$, let $s$ denote the sample standard deviation of the predictor. We define the partially standardized predictor to be
  $$ z \equiv \frac{x}{s}. $$
Note that this is an _unweighted_ standardization. We do not employ population weights at this stage, as we have already weighted our data to address the issue of bias in our latent variable model. This standardization is solely for ease of interpretation. Moreover, not that we do not de-mean our data (i.e., subtract $\bar{x}$), as several predictors are aggregations of binary variables, which are necessarily non-negative. By de-meaning such predictors, negative values are introduced, thereby muddying the interpretation of their coefficients.

Proceeding to the interpretation of our findings, we consider predictors in order of their featured complexity in the model. For example, only the main effect of `language_spanish` is estimated, whereas `personal_income` is present in two interaction terms.

  * `language_spanish`: an increase in one standard deviation of the fraction of residents whose primary spoken language is Spanish predicts an increase in the hospitalization rate of 426 residents per 100,000.

  * `employment_not_in_labor_force`: an increase in one standard deviation of the unemployment rate predicts an increase in the hospitalization rate of 2,141 residents per 100,000.

  * `birthplace_us`: given some realization of `language_english`, the estimated effect of being born in the US on the hospitalization rate is given by
  $$ -1,481 + 714 \times \text{language_english}. $$
That is, an increase in one standard deviation of the fraction of residents born in the US predicts a decrease in the hospitalization rate of 1,481 residents per 100,000, _but_ this effect is diminished in neighborhoods where the primary spoken language is English. That is, this predictor is less important in neighborhoods where most of the residents speak English.

  * `health_insurance_public`: given some realization of `personal_income`, the estimated effect of being born in the US on the hospitalization rate is given by
  $$ -1,374 + 1,643 \times \text{personal_income}. $$
That is, an increase in one standard deviation of the fraction of residents with public health insurance predicts a decrease in the hospitalization rate of 1,374 residents per 100,000, _but_ this effect is diminished in neighborhoods with higher average personal income. That is, while access to public health insurance is important, those with high income have the  privilege of being able to seek care regardless of their insurance status.

  * `personal_income`: given some realization of `health_insurance_public` and `education_bachelors`, the estimated effect of personal income on the hospitalization rate is given by
  $$ -1,418 + 1,643 \times \text{health_insurance_public} + 577 \times \text{education_bachelors}. $$
That is, an increase in one standard deviation of personal income predicts a decrease in the hospitalization rate of 1,418 residents per 100,000, _but_ this effect is diminished in neighborhoods with higher rates of public health insurance and bachelors degrees. It is most likely that in neighborhoods with lower average personal incomes, access to public health insurance and education are better predictors of the hospitalization rate than personal income.

Notes:

  * `education_bachelors_degree`: this predictor's main effect is not statistically significant, and hence it should only be interpreted in the context of its interactions (refer to `personal_income`).

  * `birthplace_us`: this predictor's main effect is not statistically significant, and hence it should only be interpreted in the context of its interactions (refer to `personal_income`).



## Diagnostics

```{r regression_diagnostics, fig.height=6.2, fig.width= 8}

lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

best_model_tidy <- fit(lm_spec, puma_hosp_rate_2020 ~ language_spanish + 
                   education_bachelors_degree +
                   birthplace_us + health_insurance_public + language_english + 
                   personal_income + employment_not_in_labor_force +
                   health_insurance_public:personal_income +
                   education_bachelors_degree:personal_income +
                   language_english:birthplace_us, data = standardized_data)


check_model(best_model_tidy, 
            check = c("linearity", "homogeneity","qq","normality", "outliers"))



```

Linearity:
It is to be observed that the relationship between independent and dependent  variables is fairly linear in our model. Thus,  we claim that the mean of the hospitalization rate in 2020 (outcome) is a linear combination of the model parameters and the predictor variables. 

Equal Variance (homoscedasticity): 
Based on the residual vs fitted plot, it is to be observed that the points in the plot are randomly dispersed around the horizontal line at 0 without showing a certain trend. This implies no violation of homoscedasticity. 

Normality of residuals: 
According to the normality probability plot, it is to be observed most of the points fall along the line. Therefore, we claim that residuals are normally distributed in our model. 

Influential points among outliers: 
According to residuals vs leverage plot, it is to be observed all points are inside the contour lines. Hence, there are no influential observations. Therefore, we claim that the residuals are independent of each other. 


```{r}

model_summary <-
  summary(best_model) %>% 
  broom::glance() %>%
  bind_rows(summary(full_model) %>% broom::glance()) %>%
  mutate(model = c("Best Model", "Full Model")) %>%
  relocate(model)

Cp <- ols_mallows_cp(best_model, full_model)

Cp <- as_tibble(Cp)

names(Cp) <- c("Mallows' Cp")

kbl(model_summary) %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(1:9, bold = T) %>%
  row_spec(1:2, bold = T, color = "white", background = "black")

kbl(Cp) %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(1, bold = T) %>%
  row_spec(1, bold = T, color = "white", background = "black")
```

Adjusted R-squared: 
We compared our model to the full model which includes all main effects of our model with all possible second-order interaction terms of main effects. It is obvious that the full model has higher R-squared (0.797) than that of our model (0.669). However, our model has a higher adjusted R-squared (0.593) than that of the full model (0.579).

Mallows’ Cp: 
Based on Mallows’ Cp criterion, we want our model to have Cp value less than or equal to the number of parameters, indicating little or no bias in the regression model. we obtained our Cp) from our model and the full model.  The Cp value is 9.5 and it is less than the number of our model parameters (11).  Therefore, we claim that our regression model has little or no bias.